{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Augini Documentation","text":""},{"location":"#ai-powered-tabular-data-framework","title":"AI-Powered Tabular Data Framework","text":"<p>Augini is a Python framework that leverages AI for data manipulation and analysis through two powerful APIs:</p>"},{"location":"#dataengineer","title":"DataEngineer","text":"<p>Transform and prepare your data with automated: - Feature engineering - Data preprocessing - Dataset scaling - Data augmentation</p>"},{"location":"#dataanalyzer","title":"DataAnalyzer","text":"<p>Extract insights from your data using: - Statistical analysis - Trend detection - Pattern recognition - Visualization integration</p>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>from augini import DataEngineer, DataAnalyzer\nimport pandas as pd\n\n# Sample customer data\ndata = pd.DataFrame({\n    'age': [25, 35, 45, 28, 52],\n    'income': [30000, 45000, 75000, 35000, 85000],\n    'purchases': [150, 450, 850, 250, 950]\n})\n\n# Initialize with your API key\nengineer = DataEngineer(api_key='your-api-key')\n\n# Generate customer segments\ndata = engineer.generate_feature(\n    df=data,\n    name='customer_segment',\n    description='Create customer segments based on age, income, and purchases',\n    output_type='category'\n)\n\n# Initialize analyzer and fit the data\nanalyzer = DataAnalyzer(api_key='your-api-key')\nanalyzer.fit(data)\n\n# Ask questions about the data\ninsights = analyzer.chat(\n    \"What are the characteristics of different customer segments? \"\n    \"Focus on age, income, and purchase patterns.\"\n)\n\nprint(insights)\n</code></pre>"},{"location":"#documentation-sections","title":"Documentation Sections","text":"<ul> <li>Quick Start &amp; API Overview - Installation and basic usage</li> <li>APIs - Detailed API documentation</li> <li>Chat Interface - Interactive data analysis</li> </ul>"},{"location":"data-analyzer/","title":"DataAnalyzer","text":"<p>The DataAnalyzer API provides an AI-powered interface for interactive data analysis through natural language queries.</p>"},{"location":"data-analyzer/#key-features","title":"Key Features","text":"<ul> <li>Natural language data analysis</li> <li>Interactive chat interface</li> <li>Context-aware responses</li> <li>Statistical insights</li> <li>Pattern detection</li> <li>Trend analysis</li> </ul>"},{"location":"data-analyzer/#basic-usage","title":"Basic Usage","text":"<pre><code>from augini import DataAnalyzer\nimport pandas as pd\n\n# Initialize with configuration\nconfig = {\n    'api_key': 'your-api-key',\n    'model': 'gpt-4-turbo-preview'\n}\n\nanalyzer = DataAnalyzer(config=config)\n\n# Load your data and prepare analyzer\ndata = pd.read_csv('your_data.csv')\nanalyzer.fit(data)\n\n# Ask questions about your data\ninsights = analyzer.chat(\"What are the main trends in this dataset?\")\nprint(insights)\n</code></pre>"},{"location":"data-analyzer/#analysis-types","title":"Analysis Types","text":""},{"location":"data-analyzer/#statistical-analysis","title":"Statistical Analysis","text":"<pre><code># Ask about statistical patterns\nstats = analyzer.chat(\n    \"What are the key statistical patterns in the data? \"\n    \"Include mean, median, and correlations in your analysis.\"\n)\n</code></pre>"},{"location":"data-analyzer/#pattern-detection","title":"Pattern Detection","text":"<pre><code># Ask about patterns in time series\npatterns = analyzer.chat(\n    \"What patterns do you see in the data over time? \"\n    \"Focus on the 'date' column.\"\n)\n</code></pre>"},{"location":"data-analyzer/#trend-analysis","title":"Trend Analysis","text":"<pre><code># Ask about trends by category\ntrends = analyzer.chat(\n    \"How do metrics vary across different categories? \"\n    \"Group the analysis by 'category' column.\"\n)\n</code></pre>"},{"location":"data-analyzer/#advanced-usage","title":"Advanced Usage","text":""},{"location":"data-analyzer/#memory-features","title":"Memory Features","text":"<pre><code># Enable conversation memory for context-aware analysis\nanalyzer = DataAnalyzer(\n    api_key='your-api-key',\n    enable_memory=True\n)\nanalyzer.fit(data)\n\n# First question\nresponse1 = analyzer.chat(\n    \"What's the average age in the dataset?\",\n    use_memory=True\n)\n\n# Follow-up question (uses context from previous question)\nresponse2 = analyzer.chat(\n    \"How does it correlate with income?\",\n    use_memory=True\n)\n</code></pre>"},{"location":"data-analyzer/#custom-analysis","title":"Custom Analysis","text":"<pre><code># Ask specific analytical questions\nanalysis = analyzer.chat(\n    \"Create a cohort analysis based on signup date. \"\n    \"Show retention rates over time and identify key patterns.\"\n)\n</code></pre>"},{"location":"data-analyzer/#configuration-options","title":"Configuration Options","text":"<pre><code>config = {\n    # Model settings\n    'model': 'gpt-4-turbo-preview',\n    'temperature': 0.7,\n\n    # Memory settings\n    'enable_memory': True,\n    'context_window_tokens': 1000,\n\n    # Debug settings\n    'debug': True,\n    'log_level': 'INFO'\n}\n</code></pre>"},{"location":"data-analyzer/#best-practices","title":"Best Practices","text":"<ol> <li>Always call fit() before chat()</li> <li>Ask clear, specific questions</li> <li>Use memory features for related queries</li> <li>Provide context in your questions</li> <li>Validate insights against raw data </li> </ol>"},{"location":"data-engineer/","title":"DataEngineer","text":"<p>The DataEngineer API provides powerful tools for feature engineering and data augmentation using AI.</p>"},{"location":"data-engineer/#quick-start","title":"Quick Start","text":"<pre><code>from augini import DataEngineer\nimport pandas as pd\n\n# Initialize with minimal configuration\nengineer = DataEngineer(api_key=\"sk-...\")\n\n# Create sample data\ndf = pd.DataFrame({\n    'CustomerID': ['C001', 'C002'],\n    'Age': [25, 45],\n    'MonthlyCharges': [50.0, 75.0]\n})\n\n# Generate a single feature\ndf = engineer.generate_feature(\n    df=df,\n    name='customer_segment',\n    description='Classify customer into segments based on spending',\n    output_type='category',\n    constraints={'categories': ['Premium', 'Regular', 'Budget']}\n)\n</code></pre>"},{"location":"data-engineer/#feature-generation-examples","title":"Feature Generation Examples","text":""},{"location":"data-engineer/#single-feature-generation","title":"Single Feature Generation","text":"<pre><code># Generate occupation prediction\ndf = engineer.generate_feature(\n    df=df,\n    name='PredictedOccupation',\n    description=\"Predict occupation based on age and spending\",\n    output_type='text'\n)\n\n# Example output:\n#   CustomerID  Age  MonthlyCharges  PredictedOccupation\n# 0      C001   25           50.0   Entry Level Professional\n# 1      C002   45           75.0   Senior Manager\n</code></pre>"},{"location":"data-engineer/#multiple-features-generation","title":"Multiple Features Generation","text":"<pre><code>augmented_df = engineer.generate_features(\n    df=df,\n    features=[\n        {\n            'name': 'ChurnRisk',\n            'description': 'Calculate churn risk score (0-100)',\n            'output_type': 'float',\n            'constraints': {'min': 0, 'max': 100}\n        },\n        {\n            'name': 'RetentionOffer',\n            'description': 'Suggest personalized retention offer',\n            'output_type': 'text'\n        }\n    ],\n    use_sync=False,  # Async processing for better performance\n    show_progress=True\n)\n\n# Example output:\n#   CustomerID  Age  MonthlyCharges  ChurnRisk  RetentionOffer\n# 0      C001   25           50.0       35.5   \"10% discount...\"\n# 1      C002   45           75.0       25.2   \"Premium upgrade...\"\n</code></pre>"},{"location":"data-engineer/#advanced-configuration","title":"Advanced Configuration","text":"<pre><code>engineer = DataEngineer(\n    api_key=\"sk-...\",\n    model=\"gpt-4o-mini\",  # Model selection\n    temperature=0.8,      # Response creativity\n    max_tokens=750,       # Max response length\n    concurrency_limit=10, # Parallel processing limit\n    base_url=\"https://openrouter.ai/api/v1\",  # Custom API endpoint\n    debug=False          # Debug mode\n)\n</code></pre>"},{"location":"data-engineer/#output-types-and-constraints","title":"Output Types and Constraints","text":"<pre><code># Numeric output with constraints\ndf = engineer.generate_feature(\n    df=df,\n    name='risk_score',\n    description='Calculate risk score',\n    output_type='float',\n    constraints={\n        'min': 0,\n        'max': 100,\n        'step': 0.1\n    }\n)\n\n# Categorical output with defined categories\ndf = engineer.generate_feature(\n    df=df,\n    name='segment',\n    description='Customer segment',\n    output_type='category',\n    constraints={\n        'categories': ['Premium', 'Regular', 'Budget']\n    }\n)\n</code></pre>"},{"location":"data-engineer/#key-features","title":"Key Features","text":"<ul> <li>AI-powered feature generation</li> <li>Automated feature engineering</li> <li>Multiple output types support (float, category, text)</li> <li>Batch processing capabilities</li> <li>Custom constraints and validations</li> </ul>"},{"location":"data-engineer/#basic-usage","title":"Basic Usage","text":"<pre><code>from augini import DataEngineer\nimport pandas as pd\n\n# Initialize with configuration\nconfig = {\n    'api_key': 'your-api-key',\n    'model': 'gpt-4-turbo-preview'\n}\n\nengineer = DataEngineer(config=config)\n\n# Load your data\ndata = pd.read_csv('your_data.csv')\n\n# Generate a new feature\nresult = engineer.generate_feature(\n    df=data,\n    name='risk_score',\n    description='Calculate customer risk score based on transaction history',\n    output_type='float'\n)\n</code></pre>"},{"location":"data-engineer/#feature-generation","title":"Feature Generation","text":""},{"location":"data-engineer/#single-feature-generation_1","title":"Single Feature Generation","text":"<pre><code># Generate a specific feature\nfeature_data = engineer.generate_feature(\n    df=data,\n    name='customer_segment',\n    description=\"Create customer segments based on behavior\",\n    output_type='category',\n    source_columns=['age', 'income', 'purchase_history']\n)\n</code></pre>"},{"location":"data-engineer/#multiple-features-generation_1","title":"Multiple Features Generation","text":"<pre><code># Generate multiple features at once\nfeatures_data = engineer.generate_features(\n    df=data,\n    features=[\n        {\n            'name': 'lifetime_value',\n            'description': \"Predict customer lifetime value\",\n            'output_type': 'float',\n            'constraints': {'min': 0}\n        },\n        {\n            'name': 'churn_risk',\n            'description': \"Assess customer churn risk\",\n            'output_type': 'category'\n        }\n    ]\n)\n</code></pre>"},{"location":"data-engineer/#advanced-usage","title":"Advanced Usage","text":""},{"location":"data-engineer/#custom-constraints","title":"Custom Constraints","text":"<pre><code># Generate feature with constraints\nresult = engineer.generate_feature(\n    df=data,\n    name='satisfaction_score',\n    description='Calculate customer satisfaction score',\n    output_type='float',\n    constraints={\n        'min': 0,\n        'max': 100,\n        'step': 0.1\n    }\n)\n</code></pre>"},{"location":"data-engineer/#batch-processing","title":"Batch Processing","text":"<pre><code># Handle large datasets efficiently\nresult = engineer.generate_feature(\n    df=large_data,\n    name='risk_score',\n    description='Calculate risk score',\n    output_type='float',\n    batch_size=32\n)\n</code></pre>"},{"location":"data-engineer/#configuration-options","title":"Configuration Options","text":"<pre><code>config = {\n    # Model settings\n    'model': 'gpt-4-turbo-preview',\n    'temperature': 0.7,\n\n    # Processing settings\n    'batch_size': 32,\n    'concurrency_limit': 5,\n\n    # Performance settings\n    'enable_cache': True,\n    'cache_ttl': 3600\n}\n</code></pre>"},{"location":"data-engineer/#best-practices","title":"Best Practices","text":"<ol> <li>Start with a small subset of data to test feature generation</li> <li>Use descriptive feature names and clear descriptions</li> <li>Specify appropriate output types and constraints</li> <li>Use batch processing for large datasets</li> <li>Monitor and validate generated features before production use </li> </ol>"},{"location":"provider-agnostic/","title":"Provider Agnostic Usage","text":"<p>Augini is designed to work with different LLM providers. Here's how to configure it for various providers.</p>"},{"location":"provider-agnostic/#openrouter-integration","title":"OpenRouter Integration","text":"<pre><code>from augini import DataEngineer, DataAnalyzer\n\n# Configure for OpenRouter\nengineer = DataEngineer(\n    api_key=\"your-openrouter-key\",\n    model=\"gpt-4o-mini\",  # OpenRouter model name\n    base_url=\"https://openrouter.ai/api/v1\",\n    temperature=0.8,\n    max_tokens=750\n)\n\n# Example output:\n# Using OpenRouter API endpoint...\n# Model set to gpt-4o-mini\n</code></pre>"},{"location":"provider-agnostic/#openai-direct-integration","title":"OpenAI Direct Integration","text":"<pre><code># Configure for OpenAI\nengineer = DataEngineer(\n    api_key=\"sk-...\",  # Your OpenAI API key\n    model=\"gpt-4-turbo-preview\",\n    temperature=0.8,\n    max_tokens=750\n)\n\n# Example output:\n# Using OpenAI API endpoint...\n# Model set to gpt-4-turbo-preview\n</code></pre>"},{"location":"provider-agnostic/#azure-openai-integration","title":"Azure OpenAI Integration","text":"<pre><code># Configure for Azure OpenAI\nengineer = DataEngineer(\n    api_key=\"your-azure-key\",\n    base_url=\"https://your-resource.openai.azure.com\",\n    model=\"gpt-4\",\n    api_version=\"2024-02-15-preview\"\n)\n</code></pre>"},{"location":"provider-agnostic/#configuration-options","title":"Configuration Options","text":"<p>Common configuration parameters across providers:</p> <pre><code>config = {\n    'api_key': str,        # API key for authentication\n    'base_url': str,       # API endpoint URL\n    'model': str,          # Model identifier\n    'temperature': float,  # Response creativity (0.0-1.0)\n    'max_tokens': int,    # Maximum response length\n    'timeout': int,       # Request timeout in seconds\n}\n</code></pre>"},{"location":"quick-start/","title":"Quick Start Guide","text":"<p>This guide will help you get started with Augini quickly using a practical example.</p>"},{"location":"quick-start/#installation","title":"Installation","text":"<pre><code>pip install augini\n</code></pre>"},{"location":"quick-start/#basic-configuration","title":"Basic Configuration","text":"<p>Configure Augini using environment variables or a configuration file:</p> <pre><code>from augini.config import AuginiConfig\n\n# Using environment variables\nconfig = AuginiConfig.from_env()\n\n# Or using a YAML file\nconfig = AuginiConfig.from_file('config.yaml')\n</code></pre> <p>Example <code>config.yaml</code>: <pre><code>api_key: your-api-key\nmodel: gpt-4-turbo-preview\n</code></pre></p>"},{"location":"quick-start/#practical-example","title":"Practical Example","text":"<p>Let's walk through a complete example using a sample customer dataset:</p> <pre><code>from augini import DataEngineer, DataAnalyzer\nimport pandas as pd\n\n# Create a sample customer dataset\ndata = pd.DataFrame({\n    'customer_id': range(1, 6),\n    'age': [25, 35, 45, 28, 52],\n    'income': [30000, 45000, 75000, 35000, 85000],\n    'purchase_amount': [150, 450, 850, 250, 950],\n    'location': ['NY', 'CA', 'TX', 'FL', 'WA']\n})\n\n# Initialize Augini components\nengineer = DataEngineer(api_key='your-api-key')\nanalyzer = DataAnalyzer(api_key='your-api-key')\n\n# Step 1: Generate new features using DataEngineer\nengineered_data = engineer.generate_feature(\n    df=data,\n    name='customer_segment',\n    description=\"Create customer segments based on age, income, and purchase_amount\",\n    output_type='category'\n)\n\nprint(\"Generated Features:\")\nprint(engineered_data[['customer_id', 'customer_segment']])\n\n# Step 2: Analyze the data using DataAnalyzer\nanalyzer.fit(engineered_data)  # Prepare the analyzer with our data\ninsights = analyzer.chat(\n    \"What are the key characteristics of each customer segment? \"\n    \"Focus on average age, income, and purchase amounts.\"\n)\n\nprint(\"\\nSegment Analysis:\")\nprint(insights)\n\n# Step 3: Ask follow-up questions\nfollow_up = analyzer.chat(\n    \"Which segment shows the highest potential for growth?\",\n    use_memory=True  # Use context from previous question\n)\n\nprint(\"\\nFollow-up Analysis:\")\nprint(follow_up)\n</code></pre> <p>This example demonstrates: 1. Creating a sample dataset 2. Using DataEngineer to add customer segmentation 3. Using DataAnalyzer to understand segments through natural language 4. Asking follow-up questions with context memory</p>"},{"location":"quick-start/#common-operations","title":"Common Operations","text":""},{"location":"quick-start/#feature-generation","title":"Feature Generation","text":"<pre><code># Generate a single feature\nfeature_data = engineer.generate_feature(\n    df=data,\n    name='risk_score',\n    description=\"Generate risk score based on customer behavior\",\n    output_type='float'\n)\n\n# Generate multiple features\nfeatures_data = engineer.generate_features(\n    df=data,\n    features=[\n        {\n            'name': 'lifetime_value',\n            'description': \"Predict customer lifetime value\",\n            'output_type': 'float'\n        },\n        {\n            'name': 'churn_risk',\n            'description': \"Assess customer churn risk\",\n            'output_type': 'category'\n        }\n    ]\n)\n</code></pre>"},{"location":"quick-start/#interactive-analysis","title":"Interactive Analysis","text":"<pre><code># First prepare the analyzer\nanalyzer.fit(data)\n\n# Ask questions about your data\nbasic_insights = analyzer.chat(\n    \"What are the main patterns in purchase behavior?\"\n)\n\n# Ask follow-up questions\ndetailed_insights = analyzer.chat(\n    \"How do these patterns vary by age group?\",\n    use_memory=True\n)\n</code></pre> <p>For more detailed information about each component, check the API documentation: - DataEngineer API - DataAnalyzer API - Chat Interface</p> <p>For more detailed information, check the API Reference or Advanced Topics. </p>"}]}