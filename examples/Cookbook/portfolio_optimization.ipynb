{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install yfinance\n",
    "%pip install augini\n",
    "%pip install PyPortfolioOpt\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onlyartist9/Projects/Tabularis/augini/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from pypfopt import EfficientFrontier, expected_returns, risk_models\n",
    "from augini import Augini\n",
    "import os\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using API key from environment variable.\n"
     ]
    }
   ],
   "source": [
    "# Step 0: Input your api key\n",
    "def get_api_key():\n",
    "    api_key = os.environ.get('OPENROUTER_TOKEN')\n",
    "    if api_key:\n",
    "        print(\"Using API key from environment variable.\")\n",
    "        return api_key\n",
    "    else:\n",
    "        api_key = input(\"Enter your API key manually: \")\n",
    "        return api_key\n",
    "\n",
    "# Set up Augini\n",
    "api_key = get_api_key()\n",
    "augini = Augini(api_key=api_key, use_openrouter=True, model='openai/gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stock price data sample:\n",
      "                                 META        AAPL        AMZN        NFLX  \\\n",
      "Date                                                                        \n",
      "2023-12-27 00:00:00-05:00  356.468323  192.208359  153.339996  491.790009   \n",
      "2023-12-28 00:00:00-05:00  356.956482  192.636276  153.380005  490.510010   \n",
      "2023-12-29 00:00:00-05:00  352.613068  191.591385  151.940002  486.880005   \n",
      "2024-01-02 00:00:00-05:00  344.972260  184.734970  149.929993  468.500000   \n",
      "2024-01-03 00:00:00-05:00  343.159180  183.351746  148.470001  470.260010   \n",
      "\n",
      "                                GOOGL  \n",
      "Date                                   \n",
      "2023-12-27 00:00:00-05:00  139.862976  \n",
      "2023-12-28 00:00:00-05:00  139.723480  \n",
      "2023-12-29 00:00:00-05:00  139.185440  \n",
      "2024-01-02 00:00:00-05:00  137.670929  \n",
      "2024-01-03 00:00:00-05:00  138.418228  \n",
      "\n",
      "Basic statistics for each stock:\n",
      "             META        AAPL        AMZN        NFLX       GOOGL\n",
      "count  253.000000  253.000000  253.000000  253.000000  253.000000\n",
      "mean   505.806555  206.242863  183.961660  667.537312  162.914085\n",
      "std     64.066229   25.397067   17.415543  109.848762   15.448131\n",
      "min    343.159180  164.405121  144.570007  468.500000  130.925369\n",
      "25%    473.182465  183.486069  174.990005  607.150024  150.547455\n",
      "50%    503.273560  212.829224  183.149994  647.500000  163.882187\n",
      "75%    560.897522  226.960007  189.080002  706.130005  174.357956\n",
      "max    632.170044  259.019989  232.929993  936.559998  196.660004\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Initial Data Collection\n",
    "\n",
    "tickers = ['META', 'AAPL', 'AMZN', 'NFLX', 'GOOGL']\n",
    "\n",
    "def get_stock_data(tickers, period='1y'):\n",
    "    data = pd.DataFrame()\n",
    "    for ticker in tickers:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        hist = stock.history(period=period)\n",
    "        data[ticker] = hist['Close']\n",
    "    return data\n",
    "\n",
    "# Get stock price data\n",
    "stock_data = get_stock_data(tickers)\n",
    "print(\"\\nStock price data sample:\")\n",
    "print(stock_data.head())\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nBasic statistics for each stock:\")\n",
    "print(stock_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recent news data summary:\n",
      "Total news articles retrieved: 50\n",
      "\n",
      "Articles per ticker:\n",
      "ticker\n",
      "AMZN     10\n",
      "AAPL     10\n",
      "NFLX     10\n",
      "GOOGL    10\n",
      "META     10\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample of recent news:\n",
      "   ticker                                              title  \\\n",
      "24   AMZN  Amazon Shares Slip 2.5% as Market Awaits 2025 ...   \n",
      "17   AAPL  The White House Estimates RealPage Software Ca...   \n",
      "32   NFLX  Netflix Shatters Records with NFL Debut While ...   \n",
      "20   AMZN  Analyst Explains Why Amazon.com (AMZN) Is The ...   \n",
      "45  GOOGL  The AI stock trade is starting to shift beyond...   \n",
      "\n",
      "                  date  \n",
      "24 2024-12-27 15:32:20  \n",
      "17 2024-12-27 15:30:16  \n",
      "32 2024-12-27 15:24:19  \n",
      "20 2024-12-27 15:21:58  \n",
      "45 2024-12-27 15:11:33  \n",
      "\n",
      "Missing values in each column:\n",
      "ticker         0\n",
      "title          0\n",
      "description    0\n",
      "link           0\n",
      "publisher      0\n",
      "date           0\n",
      "dtype: int64\n",
      "\n",
      "News date range:\n",
      "Earliest: 2024-12-26 09:03:32\n",
      "Latest: 2024-12-27 15:32:20\n"
     ]
    }
   ],
   "source": [
    "# Step 2: News Data Collection using yfinance Search\n",
    "\n",
    "def get_stock_news(tickers, news_count=10):\n",
    "    news_data = []\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            # Use Search class to get news\n",
    "            search_results = yf.Search(\n",
    "                query=ticker,\n",
    "                news_count=news_count,\n",
    "                max_results=news_count\n",
    "            )\n",
    "            \n",
    "            if hasattr(search_results, 'news') and search_results.news:\n",
    "                for news_item in search_results.news:\n",
    "                    try:\n",
    "                        news_data.append({\n",
    "                            'ticker': ticker,\n",
    "                            'title': news_item.get('title', ''),\n",
    "                            'description': news_item.get('description', ''),\n",
    "                            'link': news_item.get('link', ''),\n",
    "                            'publisher': news_item.get('publisher', ''),\n",
    "                            'date': pd.to_datetime(news_item.get('providerPublishTime', pd.Timestamp.now().timestamp()), unit='s')\n",
    "                        })\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing news item for {ticker}: {str(e)}\")\n",
    "                        continue\n",
    "            else:\n",
    "                print(f\"No news found for {ticker}\")\n",
    "                news_data.append({\n",
    "                    'ticker': ticker,\n",
    "                    'title': 'No recent news available',\n",
    "                    'description': 'No description available',\n",
    "                    'link': '',\n",
    "                    'publisher': '',\n",
    "                    'date': pd.Timestamp.now()\n",
    "                })\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching news for {ticker}: {str(e)}\")\n",
    "            news_data.append({\n",
    "                'ticker': ticker,\n",
    "                'title': 'Failed to fetch news',\n",
    "                'description': 'Error in data retrieval',\n",
    "                'link': '',\n",
    "                'publisher': '',\n",
    "                'date': pd.Timestamp.now()\n",
    "            })\n",
    "    \n",
    "    # Create DataFrame\n",
    "    news_df = pd.DataFrame(news_data)\n",
    "    \n",
    "    # Sort by date (most recent first)\n",
    "    news_df = news_df.sort_values('date', ascending=False)\n",
    "    \n",
    "    return news_df\n",
    "\n",
    "# Fetch news data\n",
    "news_df = get_stock_news(tickers)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nRecent news data summary:\")\n",
    "print(f\"Total news articles retrieved: {len(news_df)}\")\n",
    "print(\"\\nArticles per ticker:\")\n",
    "print(news_df['ticker'].value_counts())\n",
    "\n",
    "print(\"\\nSample of recent news:\")\n",
    "# Display sample showing ticker, title, and date\n",
    "print(news_df[['ticker', 'title', 'date']].head())\n",
    "\n",
    "# Quality checks\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(news_df.isnull().sum())\n",
    "\n",
    "# Date range of news\n",
    "print(\"\\nNews date range:\")\n",
    "print(f\"Earliest: {news_df['date'].min()}\")\n",
    "print(f\"Latest: {news_df['date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original vs Augmented Data Sample:\n",
      "   ticker                                              title sentiment\n",
      "24   AMZN  Amazon Shares Slip 2.5% as Market Awaits 2025 ...   Bearish\n",
      "17   AAPL  The White House Estimates RealPage Software Ca...   Bullish\n",
      "32   NFLX  Netflix Shatters Records with NFL Debut While ...   Bullish\n",
      "20   AMZN  Analyst Explains Why Amazon.com (AMZN) Is The ...   Bearish\n",
      "45  GOOGL  The AI stock trade is starting to shift beyond...   Bearish\n",
      "\n",
      "Sentiment Distribution:\n",
      "sentiment\n",
      "Bullish    22\n",
      "Bearish    18\n",
      "Neutral    10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Synthetic Data Generation using Augini\n",
    "\n",
    "sentiment_prompt = \"\"\"\n",
    "Analyze the news title to determine market sentiment.\n",
    "Generate synthetic sentiment labels across three categories:\n",
    "- Bearish (negative outlook)\n",
    "- Neutral (stable outlook)\n",
    "- Bullish (positive outlook)\n",
    "Base the sentiment on market implications and investor perspective. The name of the column returned will be 'sentiment'.\n",
    "\"\"\"\n",
    "\n",
    "# Generate synthetic sentiment data\n",
    "augmented_df = augini.augment_single(\n",
    "    news_df,\n",
    "    column_name=\"sentiment\",\n",
    "    custom_prompt=sentiment_prompt,\n",
    "    use_sync=False\n",
    ")\n",
    "\n",
    "print(\"\\nOriginal vs Augmented Data Sample:\")\n",
    "print(augmented_df[['ticker', 'title', 'sentiment']].head())\n",
    "\n",
    "# Convert sentiment to numerical scores\n",
    "sentiment_scores = {\n",
    "    'Bearish': -1,\n",
    "    'Neutral': 0,\n",
    "    'Bullish': 1\n",
    "}\n",
    "\n",
    "augmented_df['sentiment_score'] = augmented_df['sentiment'].map(sentiment_scores)\n",
    "\n",
    "print(\"\\nSentiment Distribution:\")\n",
    "print(augmented_df['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Data Overview 📊\n",
       "\n",
       "**Dataset Characteristics:**\n",
       "- **Shape:** 50 rows and 8 columns\n",
       "- **Data Types:** \n",
       "  - `ticker`: object\n",
       "  - `title`: object\n",
       "  - `description`: object\n",
       "  - `link`: object\n",
       "  - `publisher`: object\n",
       "  - `date`: datetime64[ns]\n",
       "  - `sentiment`: object\n",
       "  - `sentiment_score`: int64\n",
       "\n",
       "### Column Statistics\n",
       "- **Ticker:** 5 unique values, top categories include AMZN, AAPL, NFLX, GOOGL, META (each with 10 occurrences).\n",
       "- **Title:** 43 unique values, most frequent titles are related to 'AI stock trade' and 'Magnificent Seven Stocks'.\n",
       "- **Description:** Single unique value (empty string) across all rows, indicating lack of descriptive content.\n",
       "- **Link:** 43 unique links, with some repeated multiple times.\n",
       "- **Publisher:** 16 unique publishers, with 'Insider Monkey' (8 occurrences) being the most frequent.\n",
       "- **Date:** 42 unique timestamps, indicating various publication times, predominantly on 2024-12-27.\n",
       "- **Sentiment:** 3 categories (Bullish, Bearish, Neutral) with a majority being Bullish (22 occurrences).\n",
       "- **Sentiment Score:** Mean of 0.08, median of 0.0, and a standard deviation of approximately 0.90. Scores range from -1.0 to 1.0 with slight negative skewness.\n",
       "\n",
       "### Data Quality\n",
       "- **Total Missing Values:** 0\n",
       "- **Duplicated Rows:** 0\n",
       "\n",
       "### Sample Data\n",
       "Some entries include:\n",
       "1. **Ticker:** AMZN, **Title:** Amazon Shares Slip 2.5% as Market Awaits 2025 Outlook, **Sentiment:** Bearish, **Sentiment Score:** -1\n",
       "2. **Ticker:** AAPL, **Title:** The White House Estimates RealPage Software Caused U.S. Renters To Spend An Extra $3.8 Billion Last Year, **Sentiment:** Bullish, **Sentiment Score:** 1\n",
       "3. **Ticker:** NFLX, **Title:** Netflix Shatters Records with NFL Debut While Squid Game 2 Disappoints, **Sentiment:** Bullish, **Sentiment Score:** 1\n",
       "\n",
       "### Conclusion\n",
       "The dataset is well-structured with no missing or duplicated entries. However, the description column lacks content which could limit the understanding of the articles referenced."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(augini.chat(\"Give me an overview of the data.\",df=augmented_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adjusted Expected Returns:\n",
      "META: 0.7333\n",
      "AAPL: 0.3205\n",
      "AMZN: 0.4449\n",
      "NFLX: 0.8776\n",
      "GOOGL: 0.3478\n",
      "\n",
      "Optimized Portfolio Weights:\n",
      "META: 0.2336\n",
      "AAPL: 0.1211\n",
      "AMZN: 0.0000\n",
      "NFLX: 0.6453\n",
      "GOOGL: 0.0000\n",
      "\n",
      "Portfolio Performance Metrics:\n",
      "Expected Annual Return: 77.65%\n",
      "Annual Volatility: 24.51%\n",
      "Sharpe Ratio: 3.09\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Portfolio Optimization with Sentiment Integration\n",
    "\n",
    "# Calculate base returns and risk\n",
    "returns = expected_returns.mean_historical_return(stock_data)\n",
    "cov_matrix = risk_models.sample_cov(stock_data)\n",
    "\n",
    "# Adjust expected returns based on sentiment\n",
    "sentiment_adjustment = 0.02  \n",
    "for idx, row in augmented_df.iterrows():\n",
    "    ticker = row['ticker']\n",
    "    if ticker in returns.index:\n",
    "        returns[ticker] *= (1 + sentiment_adjustment * row['sentiment_score'])\n",
    "\n",
    "print(\"\\nAdjusted Expected Returns:\")\n",
    "for ticker in returns.index:\n",
    "    print(f\"{ticker}: {returns[ticker]:.4f}\")\n",
    "\n",
    "# Optimize portfolio\n",
    "ef = EfficientFrontier(returns, cov_matrix)\n",
    "weights = ef.max_sharpe()  \n",
    "cleaned_weights = ef.clean_weights()\n",
    "\n",
    "print(\"\\nOptimized Portfolio Weights:\")\n",
    "for ticker, weight in cleaned_weights.items():\n",
    "    print(f\"{ticker}: {weight:.4f}\")\n",
    "\n",
    "# Calculate and display performance metrics\n",
    "expected_annual_return, annual_volatility, sharpe_ratio = ef.portfolio_performance()\n",
    "print(\"\\nPortfolio Performance Metrics:\")\n",
    "print(f\"Expected Annual Return: {expected_annual_return:.2%}\")\n",
    "print(f\"Annual Volatility: {annual_volatility:.2%}\")\n",
    "print(f\"Sharpe Ratio: {sharpe_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
